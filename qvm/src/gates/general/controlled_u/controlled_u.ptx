//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35404655
// Cuda compilation tools, release 12.8, V12.8.61
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_52
.address_size 64

	// .globl	controlled_u_kernel

.visible .entry controlled_u_kernel(
	.param .u64 controlled_u_kernel_param_0,
	.param .u32 controlled_u_kernel_param_1,
	.param .u32 controlled_u_kernel_param_2,
	.param .u32 controlled_u_kernel_param_3,
	.param .align 16 .b8 controlled_u_kernel_param_4[16],
	.param .align 16 .b8 controlled_u_kernel_param_5[16],
	.param .align 16 .b8 controlled_u_kernel_param_6[16],
	.param .align 16 .b8 controlled_u_kernel_param_7[16]
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd3, [controlled_u_kernel_param_0];
	ld.param.u32 	%r4, [controlled_u_kernel_param_1];
	ld.param.u32 	%r5, [controlled_u_kernel_param_2];
	ld.param.u32 	%r6, [controlled_u_kernel_param_3];
	ld.param.f64 	%fd12, [controlled_u_kernel_param_7+8];
	ld.param.f64 	%fd11, [controlled_u_kernel_param_7];
	ld.param.f64 	%fd10, [controlled_u_kernel_param_6+8];
	ld.param.f64 	%fd9, [controlled_u_kernel_param_6];
	ld.param.f64 	%fd8, [controlled_u_kernel_param_5+8];
	ld.param.f64 	%fd7, [controlled_u_kernel_param_5];
	ld.param.f64 	%fd6, [controlled_u_kernel_param_4+8];
	ld.param.f64 	%fd5, [controlled_u_kernel_param_4];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r8, %r7, %r9;
	mov.u32 	%r10, 1;
	shl.b32 	%r11, %r10, %r6;
	setp.ge.s32 	%p1, %r1, %r11;
	@%p1 bra 	$L__BB0_6;

	shl.b32 	%r13, %r10, %r4;
	and.b32  	%r14, %r13, %r1;
	setp.eq.s32 	%p2, %r14, 0;
	@%p2 bra 	$L__BB0_6;

	mov.u32 	%r15, 1;
	shl.b32 	%r2, %r15, %r5;
	xor.b32  	%r3, %r2, %r1;
	setp.lt.s32 	%p3, %r1, %r3;
	@%p3 bra 	$L__BB0_6;

	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.s32 	%rd5, %r1, 16;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.v2.f64 	{%fd13, %fd14}, [%rd1];
	mul.wide.s32 	%rd6, %r3, 16;
	add.s64 	%rd2, %rd4, %rd6;
	ld.global.v2.f64 	{%fd15, %fd16}, [%rd2];
	and.b32  	%r16, %r2, %r1;
	setp.eq.s32 	%p4, %r16, 0;
	@%p4 bra 	$L__BB0_5;

	mul.f64 	%fd17, %fd11, %fd13;
	mul.f64 	%fd18, %fd12, %fd14;
	sub.f64 	%fd19, %fd17, %fd18;
	mul.f64 	%fd20, %fd12, %fd13;
	fma.rn.f64 	%fd21, %fd11, %fd14, %fd20;
	mul.f64 	%fd22, %fd9, %fd15;
	mul.f64 	%fd23, %fd10, %fd16;
	sub.f64 	%fd24, %fd22, %fd23;
	mul.f64 	%fd25, %fd10, %fd15;
	fma.rn.f64 	%fd26, %fd9, %fd16, %fd25;
	add.f64 	%fd27, %fd19, %fd24;
	add.f64 	%fd28, %fd21, %fd26;
	st.global.v2.f64 	[%rd1], {%fd27, %fd28};
	mul.f64 	%fd29, %fd7, %fd13;
	mul.f64 	%fd30, %fd8, %fd14;
	sub.f64 	%fd31, %fd29, %fd30;
	mul.f64 	%fd32, %fd8, %fd13;
	fma.rn.f64 	%fd33, %fd7, %fd14, %fd32;
	mul.f64 	%fd34, %fd5, %fd15;
	mul.f64 	%fd35, %fd6, %fd16;
	sub.f64 	%fd36, %fd34, %fd35;
	mul.f64 	%fd37, %fd6, %fd15;
	fma.rn.f64 	%fd38, %fd5, %fd16, %fd37;
	add.f64 	%fd39, %fd31, %fd36;
	add.f64 	%fd40, %fd33, %fd38;
	st.global.v2.f64 	[%rd2], {%fd39, %fd40};
	bra.uni 	$L__BB0_6;

$L__BB0_5:
	mul.f64 	%fd41, %fd5, %fd13;
	mul.f64 	%fd42, %fd6, %fd14;
	sub.f64 	%fd43, %fd41, %fd42;
	mul.f64 	%fd44, %fd6, %fd13;
	fma.rn.f64 	%fd45, %fd5, %fd14, %fd44;
	mul.f64 	%fd46, %fd7, %fd15;
	mul.f64 	%fd47, %fd8, %fd16;
	sub.f64 	%fd48, %fd46, %fd47;
	mul.f64 	%fd49, %fd8, %fd15;
	fma.rn.f64 	%fd50, %fd7, %fd16, %fd49;
	add.f64 	%fd51, %fd43, %fd48;
	add.f64 	%fd52, %fd45, %fd50;
	st.global.v2.f64 	[%rd1], {%fd51, %fd52};
	mul.f64 	%fd53, %fd9, %fd13;
	mul.f64 	%fd54, %fd10, %fd14;
	sub.f64 	%fd55, %fd53, %fd54;
	mul.f64 	%fd56, %fd10, %fd13;
	fma.rn.f64 	%fd57, %fd9, %fd14, %fd56;
	mul.f64 	%fd58, %fd11, %fd15;
	mul.f64 	%fd59, %fd12, %fd16;
	sub.f64 	%fd60, %fd58, %fd59;
	mul.f64 	%fd61, %fd12, %fd15;
	fma.rn.f64 	%fd62, %fd11, %fd16, %fd61;
	add.f64 	%fd63, %fd55, %fd60;
	add.f64 	%fd64, %fd57, %fd62;
	st.global.v2.f64 	[%rd2], {%fd63, %fd64};

$L__BB0_6:
	ret;

}

